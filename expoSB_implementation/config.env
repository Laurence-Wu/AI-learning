# BERT Comparison Training Configuration

# Model Configuration
VOCAB_SIZE=30522
HIDDEN_SIZE=512
NUM_HIDDEN_LAYERS=8
NUM_ATTENTION_HEADS=8
INTERMEDIATE_SIZE=2048
MAX_POSITION_EMBEDDINGS=1024

# Training Configuration
BATCH_SIZE=16
LEARNING_RATE=1e-4
NUM_EPOCHS=200
MAX_SEQ_LENGTH=1024
MLM_PROBABILITY=0.15
WARMUP_STEPS=200
LOGGING_STEPS=20
EVAL_STEPS=100
SAVE_STEPS=1000
GRADIENT_ACCUMULATION_STEPS=4

# Training Options
FP16=true
SEED=42

# Data Configuration
TRAINING_DATA_FILE=training_data.txt
TRAIN_SPLIT=0.8

# Output Configuration
OUTPUT_DIR=./bert_comparison_outputs
PLOT_SAVE_PATH=bert_comparison.png
STANDARD_MODEL_SAVE_PATH=bert_standard_attention.pt
EXPOSB_MODEL_SAVE_PATH=bert_exposb_attention.pt

# Device Configuration
DEVICE=auto
