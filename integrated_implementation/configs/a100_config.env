# A100 GPU Optimized Configuration
# ================================
# Optimized for NVIDIA A100 40GB/80GB GPU
# Maximizes throughput and memory utilization

# Device Configuration
DEVICE=cuda
CUDA_VISIBLE_DEVICES=0
TORCH_CUDA_ARCH_LIST=8.0  # A100 compute capability

# Model Architecture (BERT-Large scale)
HIDDEN_SIZE=1024           # Increased from 768 for A100
NUM_HIDDEN_LAYERS=24       # BERT-Large depth
NUM_ATTENTION_HEADS=16     # More heads for better parallelization
INTERMEDIATE_SIZE=4096     # Standard 4x hidden size
MAX_POSITION_EMBEDDINGS=1024  # Longer sequences for A100 memory

# Batch Size Configuration (A100 40GB)
BATCH_SIZE=64              # Per-device batch size
GRADIENT_ACCUMULATION_STEPS=4  # Effective batch = 256
EVAL_BATCH_SIZE=128        # Larger eval batch for stability

# For A100 80GB, use these instead:
# BATCH_SIZE=128
# GRADIENT_ACCUMULATION_STEPS=2
# EVAL_BATCH_SIZE=256

# Training Configuration
NUM_EPOCHS=50              # Extended training
LEARNING_RATE=5e-4         # Higher LR for larger batch
WARMUP_STEPS=2000          # Longer warmup for stability
WEIGHT_DECAY=0.01
ADAM_BETA1=0.9
ADAM_BETA2=0.999
ADAM_EPSILON=1e-6
MAX_GRAD_NORM=1.0

# Mixed Precision Training
USE_FP16=true              # Enable automatic mixed precision
FP16_OPT_LEVEL=O2          # Aggressive mixed precision
USE_BFLOAT16=true          # A100 supports BF16 natively

# Memory Optimization
GRADIENT_CHECKPOINTING=true    # Trade compute for memory
USE_MEMORY_EFFICIENT_ATTENTION=true
CLEAR_CACHE_INTERVAL=100   # Clear cache every N steps

# DataLoader Configuration
NUM_WORKERS=8              # Parallel data loading
PIN_MEMORY=true            # Fast GPU transfer
PREFETCH_FACTOR=4          # Pre-load batches
PERSISTENT_WORKERS=true    # Keep workers alive

# Attention Mechanisms to Compare
ATTENTION_ALGORITHMS=standard,rope,exposb,absolute,rse
USE_TRITON_KERNELS=true    # Enable optimized Triton kernels

# Training Objectives
TRAINING_OBJECTIVES=mlm,clm
MLM_PROBABILITY=0.15       # Standard BERT masking
CLM_MAX_LENGTH=1024

# Optimization Features
USE_TORCH_COMPILE=true     # PyTorch 2.0 compilation
COMPILE_MODE=max-autotune  # Maximum optimization
USE_CUDNN_BENCHMARK=true   # Optimize convolutions
USE_TF32=true              # A100 TensorFloat-32

# Logging and Checkpointing
LOG_INTERVAL=50            # Log every N steps
EVAL_INTERVAL=500          # Evaluate every N steps
SAVE_INTERVAL=1000         # Save checkpoint every N steps
SAVE_TOTAL_LIMIT=5         # Keep only recent checkpoints

# Experiment Configuration
EXPERIMENT_NAME=a100_attention_comparison
OUTPUT_DIR=./outputs/a100_runs
TENSORBOARD_DIR=./tensorboard/a100
USE_WANDB=false            # Set true if using Weights & Biases

# Scheduler Configuration
SCHEDULER_TYPE=cosine_with_restarts
T_0=5000                   # First restart after N steps
T_MULT=2                   # Double period after restart
ETA_MIN=1e-6               # Minimum learning rate

# Data Configuration
DATASET_PATH=./data/preprocessed
CACHE_DIR=./cache/a100
MAX_TRAIN_SAMPLES=1000000  # Limit for faster iteration
MAX_EVAL_SAMPLES=10000

# Performance Monitoring
PROFILE_CUDA=true          # Enable CUDA profiling
PROFILE_MEMORY=true        # Track memory usage
MEASURE_FLOPS=true         # Calculate FLOPS utilization

# Attention-Specific Parameters
ROPE_THETA=10000.0         # RoPE base frequency
EXPOSB_DECAY_FACTOR=0.95   # ExpoSB decay rate
RSE_COUPLING_STRENGTH=0.1  # RSE coupling parameter

# Regularization
ATTENTION_DROPOUT=0.1
HIDDEN_DROPOUT=0.1
LABEL_SMOOTHING=0.1        # Smooth targets for better generalization

# Advanced A100 Features
USE_FLASH_ATTENTION=true   # FlashAttention for long sequences
USE_NESTED_TENSOR=true     # Efficient variable-length sequences
USE_CHANNELS_LAST=false    # Memory layout optimization

# Multi-GPU Settings (if available)
DISTRIBUTED_TRAINING=false  # Set true for multi-GPU
DDP_BACKEND=nccl           # NVIDIA collective communications
WORLD_SIZE=1               # Number of GPUs
LOCAL_RANK=0

# Debugging and Validation
DEBUG_MODE=false
DETECT_ANOMALY=false       # Disable for performance
DETERMINISTIC=false        # Non-deterministic for speed
SEED=42

# Visualization Configuration
PLOT_SMOOTHING_METHOD=gaussian
PLOT_SMOOTHING_WINDOW=5
PLOT_SMOOTHING_SIGMA=1.5
GENERATE_PLOTS=true