# BERT Comparison Training Configuration

# Model Configuration
VOCAB_SIZE=30522
HIDDEN_SIZE=512
NUM_HIDDEN_LAYERS=4
NUM_ATTENTION_HEADS=8
INTERMEDIATE_SIZE=2048
MAX_POSITION_EMBEDDINGS=512

# Training Configuration
BATCH_SIZE=8
LEARNING_RATE=5e-5
NUM_EPOCHS=800
MAX_SEQ_LENGTH=256
MLM_PROBABILITY=0.15
WARMUP_STEPS=50
LOGGING_STEPS=10
EVAL_STEPS=50
SAVE_STEPS=1000
GRADIENT_ACCUMULATION_STEPS=4

# Training Options
FP16=true
SEED=42

# Data Configuration
TRAINING_DATA_FILE=training_data.txt
TRAIN_SPLIT=0.8

# Output Configuration
OUTPUT_DIR=./bert_comparison_outputs
PLOT_SAVE_PATH=bert_comparison.png
STANDARD_MODEL_SAVE_PATH=bert_standard_attention.pt
ROPE_MODEL_SAVE_PATH=bert_rope_attention.pt

# Device Configuration
DEVICE=auto
